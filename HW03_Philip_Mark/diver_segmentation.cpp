/** Mark Philip (msp3430)
 *  File: diver_segmentation.cpp
 *
 *  This code takes in videos of divers diving, and creates a mosaic of the diver during the dive.
 *  This mosaic is saved in ./output/<video_name>.jpg.
 *
 *  For each video in ./videos/, the program first creates a background model using the MOG2
 *  algorithm on the first 500 frames of the video (actually every other frame from 300 - 500).
 *  Once this model is created, it uses MOG2 to seperate foreground and background, and tracks blobs
 *  of a predetermined approximate size (found using connected components). If a blob exists in an area where
 *  no other blobs have previously been found, the rectangle bounding that blob is saved onto the background
 *  model. This forms the mosaic, which is then saved.
 *
 *  Input:
 *      - No parameters, but expects videos to exist in "./videos/" in the current directory
 *
 *  Output:
 *      - Background model saved in ./output/ as "<video_name>_bgmodel.jpg"
 *      - Diver mosaic saved in ./outout/ as "<video_name>_mosaic.jpg"
 *
 *
 *  NOTE:
 *      - This program expects the folder "videos" to exist in the same directory as the executable.
 *      - This program expects the folder "output" to exist in the same directory as the executable.
 */

// opencv
#include "opencv2/imgcodecs.hpp"
#include "opencv2/videoio.hpp"
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>

// C/C++
#include <iostream>
#include <dirent.h>

using namespace cv;
using namespace std;

// function header
void processVideo(VideoCapture vid, char *input_vid_filename);


/** Function: main(int argc, chaer *argv[])
 *
 * Opens the video folder and calls processVideo() on each video in ./videos/
 *
 */
int main(int argc, char *argv[]) {

    // get list of files in ./videos/
    DIR *dir;
    struct dirent *ent;
    if ((dir = opendir("./videos/"))) {
        while (ent = readdir(dir)) {
            // exclude . and ..
            if (strcmp(ent->d_name, ".\0") && strcmp(ent->d_name, "..\0")) {

                // create the filename string (./videos/<filename>)
                char *filename = (char *) malloc(sizeof(char) * (10 + strlen(ent->d_name)));
                filename = strncpy(filename, "./videos/\0", 10 + strlen(ent->d_name));
                filename = strcat(filename, ent->d_name);

                // open the video file
                printf("Processing \"%s\"\n", filename);
                VideoCapture vid(filename);
                // Check if camera opened successfully
                if (!vid.isOpened()) {
                    std::cout << "Error! Can't open video file: " << filename << std::endl;
                } else {
                    // process the video
                    processVideo(vid, ent->d_name);
                    // cleanup
                    vid.release();
                }
                // free the earlier-malloced filename
                free(filename);
            }
        }
        closedir(dir);
    } else {
        // could not open directory
        std::cout << "Error! ./videos/ doesn't exist." << std::endl;
        return EXIT_FAILURE;
    }
    destroyAllWindows();
    return EXIT_SUCCESS;
}

/** Function processVideo(VideoCapture vid, char *input_vid_filename)
 *
 * @param vid                    The VideoCapture object for the video that is to be processed
 * @param input_vid_filename     The filename of the video to process
 *
 * Creates the background model for this video, then creates the diver mosaic.
 * Saves those two images in ./output/
 */
void processVideo(VideoCapture vid, char *input_vid_filename) {

    // create the mog2 object: history=100 frames, shadow_detection=false
    Ptr<BackgroundSubtractor> mog2;
    mog2 = createBackgroundSubtractorMOG2(100, 16, false);

    // current frame
    Mat frame;
    //fg mask generated by MOG2
    Mat fgMaskMOG2;


    // set up the display windows
    string original_vid_window = "Input Video";
    string fg_mask_window = "Foreground Mask (MOG2)";

    // Uncomment to display the input video and fg mask during training
    namedWindow(original_vid_window, WINDOW_FREERATIO);
    namedWindow(fg_mask_window, WINDOW_FREERATIO);
    // resize to fit nicely on my screen, keeping aspect ratio the same
    resizeWindow(original_vid_window, 360, 640);
    resizeWindow(fg_mask_window, 360, 640);
    // move to a nice spot on my screen
    //moveWindow(original_vid_window, 1700, 0);
    //moveWindow(fg_mask_window, 2061, 10);
    moveWindow(original_vid_window, 0, 0);
    moveWindow(fg_mask_window, 361, 10);


    // Read input video.
    // Train MOG2 on the first 500 frames, skipping every other frame (so actually 250 frames)
    // MOG2 initialized with memory of 100 frames, so really only the last 200 frames matter.
    // The first 300 frames are a buffer so we can (hopefully) have some movement
    int skip = 1;
    for (int frameCount = 0; frameCount < 500; frameCount++) {
        //skip every other frame
        skip = !skip;
        if (skip) {
            continue;
        }

        //read the current frame, break on end of file (or error)
        if (!vid.read(frame)) {
            cerr << "End of video reached." << endl;
            break;
        }

        // gaussian blur the frame before feeding into MOG2 to get rid of some noise
        // Mat blurred_frame;
        // GaussianBlur(frame, blurred_frame, Size(9, 9), 0, 0);

        // update the background model
        mog2->apply(frame, fgMaskMOG2);


        // Uncomment to display the input video and fg mask during training
        //show the current frame and the fg mask
        imshow(original_vid_window, frame);
        imshow(fg_mask_window, fgMaskMOG2);
        waitKey(1);

    }

    // setup to display the background model
    string mog2_background = "Background Model (press q to continue)";
    namedWindow(mog2_background, WINDOW_FREERATIO);
    // resize to fit nicely on my screen, keeping aspect ratio the same
    resizeWindow(mog2_background, 360, 640);
    //moveWindow(mog2_background, 2420, 0);
    moveWindow(mog2_background, 722, 0);

    // get and display the background model
    Mat background;
    mog2->getBackgroundImage(background);
    cout << "Displaying background model (press q to continue)" << endl;
    imshow(mog2_background, background);
    // wait until user presses 'q' to move on
    while ((char)waitKey(0) != 'q') {}
    destroyAllWindows();

    // save the background model
    cout << "Saving background model in \"./output/" << input_vid_filename << "_bgmodel.jpg\"... " << endl;
    string output_filename = "./output/" + string(input_vid_filename) + "_bgmodel.jpg";
    imwrite(output_filename, background);

    cout << "Generating mosaic..." << endl;
    // setup to display the video and foreground mask while creating the mosaic
    namedWindow(original_vid_window, WINDOW_FREERATIO);
    namedWindow(fg_mask_window, WINDOW_FREERATIO);
    // resize to fit nicely on my screen, keeping aspect ratio the same
    resizeWindow(original_vid_window, 360, 640);
    resizeWindow(fg_mask_window, 360, 640);
    // move to a nice spot on my screen
    //moveWindow(original_vid_window, 1700, 0);
    //moveWindow(fg_mask_window, 2061, 10);
    moveWindow(original_vid_window, 0, 0);
    moveWindow(fg_mask_window, 361, 10);

    // reset to beginning of video
    vid.set(CV_CAP_PROP_POS_FRAMES, 0);

    // used for keeping track of previously drawn rectangles, initialized to zeros
    Mat previous_rects = Mat::zeros(background.size(), CV_8U);

    // iterate over all frames in the video, skipping every other one
    skip = 1;
    while(true) {
        //skip every other frame
        skip = !skip;
        if (skip) {
            continue;
        }

        //read the current frame, break on end of file (or error)
        if (!vid.read(frame)) {
            cerr << "End of video reached." << endl;
            break;
        }

        //update the background model
        mog2->apply(frame, fgMaskMOG2);

        // gaussian blur to get rid of noise
        //GaussianBlur(fgMaskMOG2, fgMaskMOG2, Size(9, 9), 0, 0);

        // dilate first to make the diver a more-cohesive blob
        dilate(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(3, 3), Point(-1, -1)));

        // erode to get rid of some noise
        erode(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(3, 3), Point(-1, -1)));
        erode(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(3, 3), Point(-1, -1)));

        // dilate to blobify the diver some more
        dilate(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(3, 3), Point(-1, -1)));
        dilate(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(3, 3), Point(-1, -1)));
        dilate(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(3, 3), Point(-1, -1)));

        // get blobs
        Mat stats, centroids, labelImage;
        int nLabels = connectedComponentsWithStats(fgMaskMOG2, labelImage, stats, centroids, 8);

        // find the biggest blob > 5000px^2 and < 15000px^2
        int maxArea = 0;
        int maxIndex = -1;
        for (int idx = 0; idx < nLabels; idx++) {
            if (stats.at<int>(idx, CC_STAT_TOP) + stats.at<int>(idx, CC_STAT_HEIGHT)/2 < 1000) {
                int blob_area = stats.at<int>(idx, CC_STAT_AREA);
                if (blob_area > 5000 && blob_area > maxArea && blob_area < 15000) {
                    maxArea = blob_area;
                    maxIndex = idx;
                }
            }
        }
        //cout << "Max area: " << maxArea << endl;

        // create bounding box for blob
        if (maxIndex > -1) {
            Rect cur_rect;
            cur_rect.width = stats.at<int>(maxIndex, CC_STAT_WIDTH);
            cur_rect.height = stats.at<int>(maxIndex, CC_STAT_HEIGHT);
            cur_rect.x = stats.at<int>(maxIndex, CC_STAT_LEFT);
            cur_rect.y = stats.at<int>(maxIndex, CC_STAT_TOP);

            // Ensure that this rectangle doesn't intersect with any already used to generate the mosaic
            // Ensure that by checking if the corresponding area in previous_rects is already flagged
            if (!countNonZero(previous_rects(cur_rect))) {
                // no intersection, so add it to the mosaic and flag the corresponding area in previous_rects
                frame(cur_rect).copyTo(background(cur_rect));
                previous_rects(cur_rect).setTo(255);
            }

            // draw a bounding box on the input video
            rectangle(frame, cur_rect, Scalar(0, 0, 255));
        }
        // display input video (with bounding box if applicable) and fg mask
        imshow(original_vid_window, frame);
        imshow(fg_mask_window, fgMaskMOG2);
        waitKey(1);
    }
    // cleanup
    destroyAllWindows();

    // setup to display the mosiac
    string output_window = "Diver Mosaic (press q to continue)";
    namedWindow(output_window, WINDOW_FREERATIO);
    // resize to fit nicely on my screen, keeping aspect ratio the same
    resizeWindow(output_window, 360, 640);
    //moveWindow(output_window, 1700, 0);
    moveWindow(output_window, 0, 0);

    // get and display the background model (with the mosaic on it)
    cout << "Displaying diver mosaic (press q to continue)" << endl;
    imshow(output_window, background);

    // save the mosaic
    cout << "Saving the mosaic in \"./output/" << input_vid_filename << "_mosaic.jpg\"... " << endl;
    output_filename = "./output/" + string(input_vid_filename) + "_mosaic.jpg";
    imwrite(output_filename, background);

    // Uncomment to display the flagged areas in previous_rects
    string test = "test";
    namedWindow(test, WINDOW_FREERATIO);
    resizeWindow(test, 360, 640);
    moveWindow(test, 361, 0);
    imshow(test, previous_rects);


    // wait until user presses 'q' to move on
    while ((char)waitKey(0) != 'q') {}
    // cleanup
    destroyAllWindows();
}
